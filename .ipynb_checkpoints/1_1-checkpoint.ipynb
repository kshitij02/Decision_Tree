{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training decision tree on categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as num\n",
    "import random\n",
    "import math\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set(data,precentage):\n",
    "    indices=data.index.tolist()\n",
    "    test_size=(int)(precentage*len(data))\n",
    "    test_set_indices=random.sample(population=indices,k=test_size)\n",
    "    #print test_size\n",
    "    #print len(data)\n",
    "    test_set=data.loc[test_set_indices]\n",
    "    #print test_set_indices\n",
    "    train_set=data.drop(test_set_indices)\n",
    "    return train_set,test_set\n",
    "list_categorial_attribute=['Work_accident','promotion_last_5years','sales','salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and Dividing data in Training and Vaildation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")\n",
    "#data.head()\n",
    "# train_data ,test_data = train_test_set(data ,0.2)\n",
    "train_data=data.sample(frac=0.8,random_state=200)\n",
    "test_data=data.drop(train_data.index)\n",
    "test_data.head()\n",
    "# print len(test_data)\n",
    "# train_data.head()\n",
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### is_pure fuction \n",
    "Tests wheather only one type data is left or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_pure(data):\n",
    "    current=data['left']\n",
    "    if len(set(current))==1:\n",
    "        return True \n",
    "    else: \n",
    "        return False\n",
    "is_pure(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc _entropy function \n",
    "Calculates the entropy of given Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986105014037017"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_entropy(data):\n",
    "    current=data['left'].tolist()\n",
    "    if is_pure(data):\n",
    "        return 0\n",
    "    else:\n",
    "\n",
    "        num_one=current.count(1)\n",
    "        p=num_one/float(len(data.index))\n",
    "#         p=(num_one/float(len(current)))\n",
    "        entropy= ((p*math.log(p,2)) + ((1-p)*math.log(1-p,2)))*-1\n",
    "#         print entropy\n",
    "        return entropy\n",
    "        \n",
    "calc_entropy(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc_information function\n",
    "calculates the information in given data with respect each and every atttributes provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7931530920122911"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_information(data,attribute):\n",
    "    current=set(data[attribute])\n",
    "    information=0\n",
    "    for cur in current:\n",
    "        current_data=data[data[attribute]==cur]\n",
    "        current_entropy=calc_entropy(current_data)*(len(current_data.index)/float(len(data.index)))\n",
    "        information=information+current_entropy\n",
    "    return information\n",
    "calc_information(train_data,'sales')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc_information_gain function\n",
    " Calculates Information Gain of attribute on the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005457409391410595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_inforamtion_gain(data,attribute):\n",
    "    return calc_entropy(data)-calc_information(data,attribute)\n",
    "calc_inforamtion_gain(train_data,'sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best_information_gain function \n",
    "Find best information gain attributes of from all attributes of present in the list_categorial_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salary'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_information_gain(data,list_categorial_attribute):\n",
    "    dict_categorial_attribute={}\n",
    "    flag=0\n",
    "    min_v=0\n",
    "    min_at=''\n",
    "    for attr in list_categorial_attribute:\n",
    "        if flag==0:\n",
    "            min_v=calc_inforamtion_gain(data,attr)\n",
    "            min_at=attr\n",
    "            flag=1\n",
    "        elif min_v<calc_inforamtion_gain(data,attr):\n",
    "            min_v=min_v=calc_inforamtion_gain(data,attr)\n",
    "            min_at=attr\n",
    "    return min_at\n",
    "best_information_gain(train_data,list_categorial_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_tree \n",
    "build_tree fuctions builds tree on the currrently present data in the form of dictionary of dictionary,while recurrsively calling itself again and agian and assigning attribute with best_gain_attribute as root of present tree untill one of following conditions is meet-\n",
    "1. Data size become zero \n",
    "2. No Attributes is present in attribute_list \n",
    "3. All data left column value is same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(table, prev_table, attribute_list, tree = None):\n",
    "    if len(set(table['left'])) <= 1:\n",
    "        return {'leaf' : table['left'].tolist()[0]}\n",
    "    elif len(table) == 0:\n",
    "        return {'leaf': num.unique(prev_table['left'])[num.argmax(num.unique(prev_table['left'], return_counts = True)[1])]}\n",
    "    elif len(attribute_list) == 0:\n",
    "        return {'leaf': num.unique(prev_table['left'])[num.argmax(num.unique(prev_table['left'], return_counts = True)[1])]}\n",
    "    node = best_information_gain(table, attribute_list)\n",
    "    attribute_list.remove(node)\n",
    "    if tree is None:\n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "    for v in table[node].unique():\n",
    "        mod_table = table.where(table[node] == v).dropna()\n",
    "        tree[node][v] = build_tree(mod_table, table, attribute_list[:])\n",
    "    return tree\n",
    "\n",
    "tree = build_tree(train_data, train_data, list_categorial_attribute[:])\n",
    "# pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_helper and predict fucntion :\n",
    "Function predict_helper is called on whole validation_data and then predict fucntion is called on each row one by one and  tree build throung train data is used to predict the result of the given row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_helper(test_data , li , tree):\n",
    "#     print(test_data.index)\n",
    "    for i in test_data.index:\n",
    "#         print test_data.loc[i]\n",
    "        predict(test_data.loc[i],li,tree)\n",
    "    return li\n",
    "def predict(row,li,tree):\n",
    "    try:\n",
    "        if tree.keys()[0]=='leaf':\n",
    "            li.append(tree['leaf'])\n",
    "        else :\n",
    "            t=tree.keys()[0]\n",
    "    #         print t\n",
    "            value=row[t]\n",
    "    #         print tree\n",
    "    #         print row[t]\n",
    "    #          print tree[row[t]]\n",
    "            predict(row,li,tree[t][value])\n",
    "    except:\n",
    "        li.append(0.0) #default value\n",
    "pridected_value=[]\n",
    "pridected_value= predict_helper(test_data,pridected_value,tree)\n",
    "# print len(pridected_value)\n",
    "# print pridected_value.count(1)\n",
    "# print pridected_value.count(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc_prefomance function\n",
    "Calcalutes the preformance of the predict values from the tree produce through the build_tree with respect to it's actual value\n",
    "And give Accuracy,Precision ,Recall & F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value = test_data['left'].tolist()\n",
    "# print len(target_value)\n",
    "def calc_preformance(target_value,pridected_value):\n",
    "    t_p=0\n",
    "    f_p=0\n",
    "    t_n=0\n",
    "    f_n=0\n",
    "    for i in range(len(target_value)):\n",
    "        if target_value[i]==0 and target_value[i]==pridected_value[i]:\n",
    "            t_n=t_n+1\n",
    "        elif target_value[i]==1 and target_value[i]==pridected_value[i]:\n",
    "            t_p=t_p+1\n",
    "        elif pridected_value[i]==1 and target_value[i]==0:\n",
    "            f_p=f_p+1\n",
    "        elif pridected_value[i]==0 and target_value[i]==1:\n",
    "            f_n=f_n+1\n",
    "    accuracy=(t_n+t_p)/float(t_n+t_p+f_p+f_n)\n",
    "    \n",
    "    precison=(t_p)/float(t_p+f_p)\n",
    "    recall=(t_p)/float(t_p+f_n)\n",
    "    a=1/precison\n",
    "    b=1/recall\n",
    "    f1_score=2/(a+b)\n",
    "    print \"Accuracy \",accuracy\n",
    "    print \"Precision \",precison\n",
    "    print \"Recall \",recall\n",
    "    print \"F1 Score\",f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Precision Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.778914590747\n",
      "Precision  1.0\n",
      "Recall  0.00200803212851\n",
      "F1 Score 0.00400801603206\n"
     ]
    }
   ],
   "source": [
    "calc_preformance(target_value,pridected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
